{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import cv2\n",
    "import keyboard\n",
    "from PIL import Image, ImageTk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchinfo import summary\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import InterpolationMode\n",
    "\n",
    "import tkinter as tk\n",
    "from tkinter import Label, Button, Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"data/\")\n",
    "image_path = data_path / \"rock_paper_scissors\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"rock\", \"paper\", \"scissors\"]\n",
    "IMAGE_PER_CLASS = 300\n",
    "\n",
    "\n",
    "def capture_dataset(cls, num_images):\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    count = 0\n",
    "\n",
    "    print(f\"Press Enter to start capture for {cls}\\nTilt and move your hand around\")\n",
    "    print(\"Press Esc to exit\")\n",
    "    keyboard.wait(\"enter\")\n",
    "    time.sleep(1)\n",
    "\n",
    "    while count < num_images:\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        cv2.putText(frame, \n",
    "                    f\"Class: {cls} | Image: {count+1}/{num_images}\", \n",
    "                    (10, 30), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                    0.7, \n",
    "                    (0, 0, 0), \n",
    "                    2)\n",
    "        cv2.imshow(\"Webcam\", frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == 27:\n",
    "            print(\"Exiting\")\n",
    "            break\n",
    "\n",
    "        save_path = os.path.join(image_path, cls, f\"{cls}_{count+1}.jpg\")\n",
    "        cv2.imwrite(save_path, frame)\n",
    "        count += 1\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if image_path.is_dir():\n",
    "    print(f\"Folder exists\")\n",
    "else:\n",
    "    image_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for cls in classes:\n",
    "        os.makedirs(image_path / cls, exist_ok=True)\n",
    "        capture_dataset(cls, IMAGE_PER_CLASS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = image_path/\"train\"\n",
    "test_dir = image_path/\"test\"\n",
    "\n",
    "if train_dir.is_dir() and test_dir.is_dir():\n",
    "    print(\"Dataset is organised\")\n",
    "else:\n",
    "    os.makedirs(train_dir, exist_ok = True)\n",
    "    os.makedirs(test_dir, exist_ok = True)\n",
    "\n",
    "    for cls in classes:\n",
    "        images = [file for file in os.listdir(image_path/cls) if file.endswith(\".jpg\")]\n",
    "\n",
    "        train_images, test_images = train_test_split(images, test_size=0.2, shuffle=True)\n",
    "\n",
    "        os.makedirs(train_dir/cls, exist_ok=True)\n",
    "        os.makedirs(test_dir/cls, exist_ok=True)\n",
    "\n",
    "        for image in train_images:\n",
    "            shutil.move(image_path/cls/image, train_dir/cls)\n",
    "\n",
    "        for image in test_images:\n",
    "            shutil.move(image_path/cls/image, test_dir/cls)\n",
    "\n",
    "        shutil.rmtree(image_path/cls)\n",
    "\n",
    "    print(\"Dataset organized\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT\n",
    "weights\n",
    "auto_transforms = weights.transforms()\n",
    "auto_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = torchvision.datasets.ImageFolder(train_dir, auto_transforms)\n",
    "test_data = torchvision.datasets.ImageFolder(test_dir, auto_transforms)\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    dataset=train_data, shuffle=True, num_workers=os.cpu_count(), batch_size=32\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    dataset=test_data, shuffle=False, num_workers=os.cpu_count(), batch_size=32\n",
    ")\n",
    "\n",
    "class_names = train_data.classes\n",
    "\n",
    "train_dataloader, test_dataloader, class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.efficientnet_b0(weights=weights).to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.features.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.classifier.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "output_shape = len(class_names)\n",
    "\n",
    "model.classifier = torch.nn.Sequential(\n",
    "    torch.nn.Dropout(p=0.2, inplace=True),\n",
    "    torch.nn.Linear(in_features=1280, out_features=output_shape, bias=True),\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.classifier.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model,\n",
    "    input_size=(32,3,224,224),\n",
    "    verbose=0,\n",
    "    col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "    col_width=20,\n",
    "    row_settings=[\"var_names\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(\n",
    "    model=nn.Module,\n",
    "    dataloader=DataLoader,\n",
    "    loss_fn=nn.Module,\n",
    "    optimizer=torch.optim.Optimizer,\n",
    "    device=torch.device,\n",
    ") -> Tuple[float, float]:\n",
    "    model.train()\n",
    "\n",
    "    train_loss, train_acc = 0, 0\n",
    "\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        y_pred = model(X)\n",
    "\n",
    "        loss = loss_fn(y_pred, y)\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n",
    "\n",
    "        train_acc += (y_pred_class == y).sum().item() / len(y_pred)\n",
    "\n",
    "    train_loss = train_loss / len(dataloader)\n",
    "\n",
    "    train_acc = train_acc / len(dataloader)\n",
    "\n",
    "    return train_loss, train_acc\n",
    "\n",
    "def test_step(\n",
    "    model: torch.nn.Module,\n",
    "    dataloader: torch.utils.data.DataLoader,\n",
    "    loss_fn: torch.nn.Module,\n",
    "    device: torch.device):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    test_loss, test_acc = 0, 0\n",
    "\n",
    "    with torch.inference_mode():\n",
    "\n",
    "        for batch, (X, y) in enumerate(dataloader):\n",
    "\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            test_pred_logits = model(X)\n",
    "\n",
    "            loss = loss_fn(test_pred_logits, y)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            test_pred_labels = test_pred_logits.argmax(dim=1)\n",
    "\n",
    "            test_acc += (test_pred_labels == y).sum().item() / len(test_pred_labels)\n",
    "\n",
    "    test_loss = test_loss / len(dataloader)\n",
    "\n",
    "    test_acc = test_acc / len(dataloader)\n",
    "\n",
    "    return test_loss, test_acc\n",
    "\n",
    "def train(\n",
    "    model: torch.nn.Module,\n",
    "    train_dataloader: torch.utils.data.DataLoader,\n",
    "    test_dataloader: torch.utils.data.DataLoader,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    loss_fn: torch.nn.Module,\n",
    "    epochs: int,\n",
    "    device: torch.device,\n",
    ") -> Dict[str, List]:\n",
    "\n",
    "    results = {\"train_loss\": [], \"train_acc\": [], \"test_loss\": [], \"test_acc\": []}\n",
    "\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        train_loss, train_acc = train_step(\n",
    "            model=model,\n",
    "            dataloader=train_dataloader,\n",
    "            loss_fn=loss_fn,\n",
    "            optimizer=optimizer,\n",
    "            device=device,\n",
    "        )\n",
    "        test_loss, test_acc = test_step(\n",
    "            model=model, dataloader=test_dataloader, loss_fn=loss_fn, device=device\n",
    "        )\n",
    "\n",
    "        print(\n",
    "            f\"Epoch: {epoch+1} | \"\n",
    "            f\"train_loss: {train_loss:.4f} | \"\n",
    "            f\"train_acc: {train_acc:.4f} | \"\n",
    "            f\"test_loss: {test_loss:.4f} | \"\n",
    "            f\"test_acc: {test_acc:.4f}\"\n",
    "        )\n",
    "\n",
    "        results[\"train_loss\"].append(train_loss)\n",
    "\n",
    "        results[\"train_acc\"].append(train_acc)\n",
    "\n",
    "        results[\"test_loss\"].append(test_loss)\n",
    "\n",
    "        results[\"test_acc\"].append(test_acc)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "if os.path.exists(\"model.pth\"):\n",
    "    print(\"There is a trained model\")\n",
    "    model.load_state_dict(torch.load(\"model.pth\"))\n",
    "else:\n",
    "    start_timer = timer()\n",
    "\n",
    "    results = train(\n",
    "        model=model,\n",
    "        train_dataloader=train_dataloader,\n",
    "        test_dataloader=test_dataloader,\n",
    "        optimizer=optimizer,\n",
    "        loss_fn=loss_fn,\n",
    "        epochs=5,\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "    end_timer = timer()\n",
    "\n",
    "    print(end_timer - start_timer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")\n",
    "print(\"Model saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def walk_through_dir(dir_path):\n",
    "    for dirpath, dirnames, filenames in os.walk(dir_path):\n",
    "        print(\n",
    "            f\"There are {len(dirnames)} directories and {len(filenames)}  images in '{dirpath}'.\"\n",
    "        )\n",
    "\n",
    "walk_through_dir(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict(frame) -> str:\n",
    "    img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    pil_image = Image.fromarray(img)\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(256, interpolation=InterpolationMode.BICUBIC),\n",
    "        transforms.CenterCrop(224),\n",
    "        # transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.05), \n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],  \n",
    "                                std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    model.to(device)\n",
    "    model.eval()  \n",
    "    with torch.inference_mode():\n",
    "        img_tensor = transform(pil_image).unsqueeze(0).to(device) \n",
    "        pred = model(img_tensor)\n",
    "        pred_class =  torch.argmax(torch.softmax(pred, dim=1), dim=1)\n",
    "    \n",
    "    return class_names[pred_class]\n",
    "        \n",
    "def update_score(user_score, bot_score, prediction, bot_choice):\n",
    "\n",
    "    result = \"\"\n",
    "\n",
    "    if prediction == bot_choice:\n",
    "        result = \"Draw!\"\n",
    "    elif prediction == \"scissors\" and bot_choice == \"rock\":\n",
    "        bot_score += 1\n",
    "        result = \"You Lose!\"\n",
    "    elif prediction == \"rock\" and bot_choice == \"paper\":\n",
    "        bot_score += 1\n",
    "        result = \"You Lose!\"\n",
    "    elif prediction == \"paper\" and bot_choice == \"scissors\":\n",
    "        bot_score += 1\n",
    "        result = \"You Lose!\"\n",
    "\n",
    "    elif prediction == \"scissors\" and bot_choice == \"paper\":\n",
    "        user_score += 1\n",
    "        result = \"You Win!\"\n",
    "    elif prediction == \"paper\" and bot_choice == \"rock\":\n",
    "        user_score += 1\n",
    "        result = \"You Win!\"\n",
    "    elif prediction == \"rock\" and bot_choice == \"scissors\":\n",
    "        user_score += 1\n",
    "        result = \"You Win!\"\n",
    "\n",
    "    return user_score, bot_score, result\n",
    "\n",
    "def random_bot_choice()-> str:\n",
    "    bot_choice = random.choice([\"rock\", \"scissors\", \"paper\"])\n",
    "\n",
    "    return bot_choice\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_score, bot_score = 0, 0\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Unable to access the webcam.\")\n",
    "    cap.release()\n",
    "    exit()\n",
    "\n",
    "def button_predict():\n",
    "    global user_score, bot_score\n",
    "    bot_choice = random_bot_choice()\n",
    "    label_bot_choice.config(text=bot_choice)\n",
    "    prediction = predict(cap.read()[1])\n",
    "    label_predict.config(text=prediction)\n",
    "    user_score, bot_score, result = update_score(user_score,bot_score, prediction, bot_choice)\n",
    "    label_score.config(text= f\"{user_score} : {bot_score}\")\n",
    "    label_result.config(text=result)\n",
    "    \n",
    "window = tk.Tk()\n",
    "window.geometry(\"800x400\")\n",
    "window.title(\"Rock Scissors Paper\")\n",
    "\n",
    "label = Label(window)\n",
    "label.pack(side=\"left\", pady=50, padx=25)\n",
    "\n",
    "\n",
    "def show_frames():\n",
    "    ret, frame = cap.read()\n",
    "    # print(\"Frame capture success:\", ret, \"Frame is None:\", frame is None)  # Debug output\n",
    "    if not ret or frame is None:\n",
    "        print(\"Error: Unable to capture frame.\")\n",
    "        label.after(20, show_frames) \n",
    "        return\n",
    "    try:\n",
    "        frame = cv2.resize(frame, (400, 300))\n",
    "    except Exception as e:\n",
    "        print(\"Error during resizing:\", e)\n",
    "        label.after(20, show_frames)\n",
    "        return\n",
    "    try:\n",
    "        cv2image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        img = Image.fromarray(cv2image)\n",
    "        imgtk = ImageTk.PhotoImage(image=img)\n",
    "    except Exception as e:\n",
    "        print(\"Error during image conversion:\", e)\n",
    "        label.after(20, show_frames)\n",
    "        return\n",
    "    label.imgtk = imgtk\n",
    "    label.configure(image=imgtk)\n",
    "    label.after(20, show_frames)\n",
    "\n",
    "show_frames()\n",
    "\n",
    "\n",
    "details = Frame(window)\n",
    "details.pack(pady=50)\n",
    "\n",
    "\n",
    "label_predict = Label(details, text = \"Prediction\", anchor='w', width=10)\n",
    "label_predict.grid(row=0, column=0, sticky=\"w\", padx=10, pady=10)\n",
    "\n",
    "label_score = Label(details, text= f\"{user_score} : {bot_score}\", anchor='center', width=10)\n",
    "label_score.grid(row=0, column=1, sticky=\"n\", padx=10, pady=10)\n",
    "\n",
    "label_bot_choice = Label(details, text=\"Bot\", anchor='e', width=10)\n",
    "label_bot_choice.grid(row=0, column=2, sticky=\"e\", padx=10, pady=10)\n",
    "\n",
    "label_result = Label(details, text=\"\")\n",
    "label_result.grid(row=1, column=1)\n",
    "\n",
    "predict_button = Button(details, text=\"Predict\", command=button_predict)\n",
    "predict_button.grid(row=2, column=1, pady=20) \n",
    "\n",
    "\n",
    "window.grid_columnconfigure(0, weight=1) \n",
    "window.grid_columnconfigure(1, weight=1)  \n",
    "window.grid_columnconfigure(2, weight=1)  \n",
    "window.grid_rowconfigure(0, weight=1)  \n",
    "window.grid_rowconfigure(1, weight=0)\n",
    "window.grid_rowconfigure(1, weight=0)\n",
    "\n",
    "window.mainloop()\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
